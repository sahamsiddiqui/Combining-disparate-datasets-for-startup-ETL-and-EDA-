{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0107665-86f8-4c16-bccd-6258549e3fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\saham\\\\data_projects\\\\proj05_brokerchooser'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ca4af5-ce28-4e7f-a7fd-706b1c4c92b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saham\\data_projects\\proj05_brokerchooser\\unified_data_final.csv\n"
     ]
    }
   ],
   "source": [
    "current_dir = current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir)\n",
    "\n",
    "\n",
    "#print(os.path.join(data_dir, 'unified_data_final.csv'))\n",
    "\n",
    "merged_df = pd.read_csv(os.path.join(data_dir, 'unified_data_final.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2acd7d8-b184-4921-96b8-c9d5e4554238",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# merged_df is the unified dataset we created using data processing pipeline\n",
    "#merged_df = composite_merge\n",
    "\n",
    "### 1. Customer Segmentation by Value\n",
    "# Segmenting customers into high-value and low-value groups based on 'important_score'.\n",
    "highvalue_conv = merged_df[merged_df['important_score'] > 50]\n",
    "lowvalue_conv = merged_df[merged_df['important_score'] < 50]\n",
    "\n",
    "### 2. Analyzing Conversion Volumes\n",
    "# Overview of total, high-value, and low-value conversions.\n",
    "total_conversions = merged_df['composite_key'].nunique()\n",
    "highvalue_conversions = highvalue_conv['composite_key'].nunique()\n",
    "lowvalue_conversions = lowvalue_conv['composite_key'].nunique()\n",
    "\n",
    "print(f\"Total conversions: {total_conversions}\")\n",
    "print(f\"High-value conversions: {highvalue_conversions}\")\n",
    "print(f\"Low-value conversions: {lowvalue_conversions}\")\n",
    "\n",
    "### 3. Country-Level Analysis of Conversions\n",
    "\n",
    "# a) Overall Conversion by Country (Top 10 and Others)\n",
    "top_10_countries = merged_df['country_name'].value_counts().head(10)\n",
    "others_conversions = merged_df['country_name'].value_counts()[10:].sum()\n",
    "\n",
    "top_10_with_percentage = pd.DataFrame({\n",
    "    'country_name': top_10_countries.index,\n",
    "    'conversions': top_10_countries.values\n",
    "})\n",
    "top_10_with_percentage['percentage'] = (top_10_with_percentage['conversions'] / total_conversions) * 100\n",
    "\n",
    "# Append the 'Others' row for countries not in the top 10.\n",
    "others_row = pd.DataFrame({\n",
    "    'country_name': ['Others'],\n",
    "    'conversions': [others_conversions],\n",
    "    'percentage': [(others_conversions / total_conversions) * 100]\n",
    "})\n",
    "top_10_with_percentage = pd.concat([top_10_with_percentage, others_row], ignore_index=True)\n",
    "\n",
    "# Pie Chart: Conversion Distribution by Country\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(top_10_with_percentage['conversions'], labels=top_10_with_percentage['country_name'],\n",
    "        autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Conversions by Country (Top 10 and Others)')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures pie is drawn as a circle.\n",
    "plt.show()\n",
    "\n",
    "### 4. High-Value vs. Low-Value Conversions by Country\n",
    "\n",
    "# a) High-Value Conversions\n",
    "top_10_highvalue = highvalue_conv['country_name'].value_counts().head(10)\n",
    "others_highvalue = highvalue_conv['country_name'].value_counts()[10:].sum()\n",
    "\n",
    "highvalue_with_percentage = pd.DataFrame({\n",
    "    'country_name': top_10_highvalue.index,\n",
    "    'conversions': top_10_highvalue.values\n",
    "})\n",
    "highvalue_with_percentage['percentage'] = (highvalue_with_percentage['conversions'] / len(highvalue_conv)) * 100\n",
    "\n",
    "# Add 'Others' row for high-value segment\n",
    "others_row_highvalue = pd.DataFrame({\n",
    "    'country_name': ['Others'],\n",
    "    'conversions': [others_highvalue],\n",
    "    'percentage': [(others_highvalue / len(highvalue_conv)) * 100]\n",
    "})\n",
    "highvalue_with_percentage = pd.concat([highvalue_with_percentage, others_row_highvalue], ignore_index=True)\n",
    "\n",
    "# b) Low-Value Conversions\n",
    "top_10_lowvalue = lowvalue_conv['country_name'].value_counts().head(10)\n",
    "others_lowvalue = lowvalue_conv['country_name'].value_counts()[10:].sum()\n",
    "\n",
    "lowvalue_with_percentage = pd.DataFrame({\n",
    "    'country_name': top_10_lowvalue.index,\n",
    "    'conversions': top_10_lowvalue.values\n",
    "})\n",
    "lowvalue_with_percentage['percentage'] = (lowvalue_with_percentage['conversions'] / len(lowvalue_conv)) * 100\n",
    "\n",
    "# Add 'Others' row for low-value segment\n",
    "others_row_lowvalue = pd.DataFrame({\n",
    "    'country_name': ['Others'],\n",
    "    'conversions': [others_lowvalue],\n",
    "    'percentage': [(others_lowvalue / len(lowvalue_conv)) * 100]\n",
    "})\n",
    "lowvalue_with_percentage = pd.concat([lowvalue_with_percentage, others_row_lowvalue], ignore_index=True)\n",
    "\n",
    "# Pie Chart: High-Value vs. Low-Value Conversions by Country\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# High-Value Conversions Pie Chart\n",
    "axes[0].pie(highvalue_with_percentage['conversions'], labels=highvalue_with_percentage['country_name'],\n",
    "            autopct='%1.1f%%', startangle=140)\n",
    "axes[0].set_title('High-Value Conversions by Country')\n",
    "\n",
    "# Low-Value Conversions Pie Chart\n",
    "axes[1].pie(lowvalue_with_percentage['conversions'], labels=lowvalue_with_percentage['country_name'],\n",
    "            autopct='%1.1f%%', startangle=140)\n",
    "axes[1].set_title('Low-Value Conversions by Country')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "##########################################################################################################################\n",
    "############## PAR T 2 - deep ana;ysis GPT generated to be checked\n",
    "\n",
    "# 2. UI Element Analysis\n",
    "# Top 10 UI elements for high-value conversions\n",
    "top_10_ui_elements_highvalue = highvalue_conv['ui_element'].value_counts().head(10)\n",
    "print(\"Top 10 UI elements for high-value conversions:\")\n",
    "print(top_10_ui_elements_highvalue)\n",
    "\n",
    "# Top 10 UI elements for all conversions\n",
    "top_10_ui_elements_all = merged_df['ui_element'].value_counts().head(10)\n",
    "print(\"\\nTop 10 UI elements for all conversions:\")\n",
    "print(top_10_ui_elements_all)\n",
    "\n",
    "# Get the list of UI elements\n",
    "highvalue_ui_elements_set = set(top_10_ui_elements_highvalue.index)\n",
    "all_ui_elements_set = set(top_10_ui_elements_all.index)\n",
    "\n",
    "# Common UI elements in both segments\n",
    "common_ui_elements = highvalue_ui_elements_set.intersection(all_ui_elements_set)\n",
    "print(\"\\nUI elements common in both high-value and overall conversions:\")\n",
    "print(common_ui_elements)\n",
    "\n",
    "# Unique UI elements in the high-value segment\n",
    "unique_ui_elements_highvalue = highvalue_ui_elements_set.difference(all_ui_elements_set)\n",
    "print(\"\\nUI elements unique to high-value conversions:\")\n",
    "print(unique_ui_elements_highvalue)\n",
    "\n",
    "# Venn Diagram: UI Elements for High-Value vs. All Conversions\n",
    "plt.figure(figsize=(8, 6))\n",
    "venn2([highvalue_ui_elements_set, all_ui_elements_set], set_labels=('High-Value Conversions', 'All Conversions'))\n",
    "plt.title('Venn Diagram of UI Elements for High-Value vs All Conversions')\n",
    "plt.show()\n",
    "\n",
    "# 3. Mobile vs. Desktop User Behavior\n",
    "# High-value users on mobile vs desktop\n",
    "highvalue_mobile_usage = highvalue_conv['is_mobile'].value_counts()\n",
    "print(\"High-value conversions - Mobile vs Desktop:\")\n",
    "print(highvalue_mobile_usage)\n",
    "\n",
    "# Overall mobile vs desktop usage for conversions\n",
    "all_mobile_usage = merged_df['is_mobile'].value_counts()\n",
    "print(\"Overall conversions - Mobile vs Desktop:\")\n",
    "print(all_mobile_usage)\n",
    "\n",
    "# 4. Page Category Analysis\n",
    "# Top page categories for high-value conversions\n",
    "top_page_categories_highvalue = highvalue_conv['page_name'].value_counts().head(10)\n",
    "print(\"Top 5 page categories for high-value conversions:\")\n",
    "print(top_page_categories_highvalue)\n",
    "\n",
    "# Top page categories for all conversions\n",
    "top_page_categories_all = merged_df['page_name'].value_counts().head(10)\n",
    "print(\"Top 5 page categories for all conversions:\")\n",
    "print(top_page_categories_all)\n",
    "\n",
    "# Top page categories for low-value conversions\n",
    "top_page_categories_lowvalue = lowvalue_conv['page_name'].value_counts().head(10)\n",
    "print(\"Top 5 page categories for low-value conversions:\")\n",
    "print(top_page_categories_lowvalue)\n",
    "\n",
    "# 5. Session Analysis\n",
    "# Unique values in the dataset\n",
    "total_unique_conversions = merged_df['id'].nunique()\n",
    "total_unique_sessions = merged_df['session_id'].nunique()\n",
    "print(f\"Total unique conversions: {total_unique_conversions}\")\n",
    "print(f\"Total unique sessions: {total_unique_sessions}\")\n",
    "\n",
    "# Identifying sessions with multiple conversions\n",
    "session_counts = merged_df['session_id'].value_counts()\n",
    "multiple_conversion_sessions = session_counts[session_counts > 1].index\n",
    "\n",
    "# Filter the dataset for these sessions\n",
    "multiple_conv_df = merged_df[merged_df['session_id'].isin(multiple_conversion_sessions)]\n",
    "\n",
    "# Average Importance Score for Multiple Conversions\n",
    "avg_importance_multiple_conversions = multiple_conv_df['important_score'].mean()\n",
    "print(f\"Average importance score for sessions with multiple conversions: {avg_importance_multiple_conversions}\")\n",
    "\n",
    "# Visualization: Distribution of Importance Scores for Multiple Conversion Sessions\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(multiple_conv_df['important_score'], bins=20, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Importance Scores for Sessions with Multiple Conversions')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Top 5 UI Elements for Multiple Conversions\n",
    "top_ui_elements_multiple = multiple_conv_df['ui_element'].value_counts().head(5)\n",
    "print(\"Top 5 UI elements for sessions with multiple conversions:\")\n",
    "print(top_ui_elements_multiple)\n",
    "\n",
    "# Visualization: Top UI Elements for Multiple Conversions\n",
    "plt.figure(figsize=(8, 5))\n",
    "top_ui_elements_multiple.plot(kind='bar', color='salmon')\n",
    "plt.title('Top 5 UI Elements for Sessions with Multiple Conversions')\n",
    "plt.xlabel('UI Element')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Top 5 Page Categories for Multiple Conversions\n",
    "top_page_categories_multiple = multiple_conv_df['page_name'].value_counts().head(5)\n",
    "print(\"Top 5 Page Categories for sessions with multiple conversions:\")\n",
    "print(top_page_categories_multiple)\n",
    "\n",
    "# Visualization: Top Page Categories for Multiple Conversions\n",
    "plt.figure(figsize=(8, 5))\n",
    "top_page_categories_multiple.plot(kind='bar', color='lightgreen')\n",
    "plt.title('Top 5 Page Categories for Sessions with Multiple Conversions')\n",
    "plt.xlabel('Page Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Checking if the same user converted multiple times in one session\n",
    "unique_users_per_session = multiple_conv_df.groupby('session_id')['id'].nunique()\n",
    "multi_conversion_same_user = unique_users_per_session[unique_users_per_session > 1].count()\n",
    "print(f\"Number of sessions where the same user converted multiple times: {multi_conversion_same_user}\")\n",
    "\n",
    "# Summary of sessions with multiple conversions\n",
    "total_multi_conversion_sessions = len(multiple_conv_df['session_id'].unique())\n",
    "percentage_multi_conversion_same_user = (multi_conversion_same_user / total_multi_conversion_sessions) * 100\n",
    "print(f\"Total sessions with multiple conversions: {total_multi_conversion_sessions}\")\n",
    "print(f\"Percentage of sessions where the same user converted multiple times: {percentage_multi_conversion_same_user:.2f}%\")\n",
    "\n",
    "# Percentage of sessions using mobile in multiple conversion sessions\n",
    "mobile_usage_multiple_conversion = multiple_conv_df['is_mobile'].value_counts(normalize=True) * 100\n",
    "mobile_percentage = mobile_usage_multiple_conversion.get(1, 0)\n",
    "print(f\"Percentage of sessions using mobile in multiple conversion sessions: {mobile_percentage:.2f}%\")\n",
    "\n",
    "# Top 5 countries in sessions with multiple conversions\n",
    "top_countries_multiple_conversion = multiple_conv_df['country_name'].value_counts().head(5)\n",
    "print(\"Top 5 countries in sessions with multiple conversions:\")\n",
    "print(top_countries_multiple_conversion)\n",
    "\n",
    "#######################################################################################################################\n",
    "############## PAR T 3 - deep ana;ysis GPT generated to be checked\n",
    "# 4. Important Score Binned in Intervals of 10\n",
    "# Ensure 'important_score' column is numeric\n",
    "merged_df['important_score'] = pd.to_numeric(merged_df['important_score'], errors='coerce')\n",
    "\n",
    "# Bin the scores into intervals of 10\n",
    "bins = range(0, 101, 10)  # Scores from 0 to 100\n",
    "merged_df['score_bin'] = pd.cut(merged_df['important_score'], bins=bins)\n",
    "\n",
    "# Count distinct conversions for each bin\n",
    "conversion_by_score_bin = merged_df.groupby('score_bin')['id'].nunique()\n",
    "print(\"Number of distinct conversions by important score bins:\")\n",
    "print(conversion_by_score_bin)\n",
    "\n",
    "# Plot the distribution of conversions by important score bins\n",
    "plt.figure(figsize=(8, 6))\n",
    "conversion_by_score_bin.plot(kind='bar', title='Conversions by Important Score Bins', color='lightblue')\n",
    "plt.ylabel('Number of Distinct Conversions')\n",
    "plt.xlabel('Important Score Bins')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Insight: \n",
    "# The frequency of users in the 0-10 score bin is high (about 62% of all users). \n",
    "# These users represent lower-value investors, indicating that BrokerChooser excels in converting beginner or low-investment users.\n",
    "\n",
    "# Deep Analysis of Repeated Sessions\n",
    "# Filter the dataset to keep only rows with multiple conversions within the same session\n",
    "multiple_conv_sessions = merged_df[merged_df['session_id'].isin(multiple_conversion_sessions)]\n",
    "\n",
    "# Sort by session_id and created_at timestamp\n",
    "multiple_conv_sessions_sorted = multiple_conv_sessions.sort_values(by=['session_id', 'created_at'])\n",
    "\n",
    "# Calculate the time difference between consecutive conversions in the same session\n",
    "multiple_conv_sessions_sorted['time_diff'] = multiple_conv_sessions_sorted.groupby('session_id')['created_at'].diff()\n",
    "\n",
    "# Display examples where multiple conversions have different times\n",
    "multiple_conv_sessions_sorted_time_diff = multiple_conv_sessions_sorted[multiple_conv_sessions_sorted['time_diff'].notna()]\n",
    "print(f\"Number of rows with time differences between conversions: {len(multiple_conv_sessions_sorted_time_diff)}\")\n",
    "\n",
    "# Sort by time difference in descending order\n",
    "multiple_conv_sessions_sorted_time_diff_desc = multiple_conv_sessions_sorted_time_diff.sort_values(by='time_diff', ascending=False)\n",
    "multiple_conv_sessions_sorted_time_diff_desc.head(10)\n",
    "\n",
    "# Convert 'time_diff' to days for better interpretation\n",
    "multiple_conv_sessions_sorted_time_diff_desc['time_diff_days'] = multiple_conv_sessions_sorted_time_diff_desc['time_diff'].dt.days\n",
    "\n",
    "# Frequency of each time_diff (in days)\n",
    "time_diff_freq = multiple_conv_sessions_sorted_time_diff_desc['time_diff_days'].value_counts().sort_index()\n",
    "\n",
    "# Plot the frequency of conversions by time difference in days\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x=time_diff_freq.index, y=time_diff_freq.values, marker='o', color='green')\n",
    "plt.title('Frequency of Conversions by Time Difference (Days) in the Same Session')\n",
    "plt.xlabel('Time Difference (Days)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
